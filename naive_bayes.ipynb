{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Spam Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes is a family of probabilistic algorithms based on Bayes' Theorem, commonly used in machine learning for classification tasks. Despite its simplicity, it is effective and often used for text classification problems, such as spam detection, sentiment analysis, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The \"naive\" part of Naive Bayes comes from the assumption that the features (input variables) are independent of each other given the class label. This means the presence of one feature does not affect the presence of another, which is often not true in reality but simplifies the computation.\n",
    "\n",
    "##### In text classification, the features are typically word frequencies or occurrences in a document. The model calculates the probability that a given document belongs to a particular class (e.g., \"spam\" or \"ham\") based on the words it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\R-m-a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Ensure you have downloaded the necessary NLTK data\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    ps = PorterStemmer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([ps.stem(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Function to read files\n",
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "# Function to create DataFrame from directory\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "\n",
    "    return DataFrame(rows, index=index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.89      1.00      0.94       482\n",
      "        spam       1.00      0.47      0.64       118\n",
      "\n",
      "    accuracy                           0.90       600\n",
      "   macro avg       0.94      0.74      0.79       600\n",
      "weighted avg       0.91      0.90      0.88       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "data = DataFrame({'message': [], 'class': []})\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"D:/MLCourse/emails/spam\", \"spam\")])\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"D:/MLCourse/emails/ham\", \"ham\")])\n",
    "\n",
    "# Apply text preprocessing\n",
    "data['message'] = data['message'].apply(preprocess)\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the message texts\n",
    "counts = vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, data['class'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Free class now!!!\n",
      "Predicted Class: ham\n",
      "Review: Hi Bob, how about a game of golf tomorrow?\n",
      "Predicted Class: ham\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example predictions\n",
    "examples = ['Free class now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "\n",
    "# Display example predictions\n",
    "for review, prediction in zip(examples, predictions):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Class: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using countvectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\R-m-a\\AppData\\Local\\Temp\\ipykernel_37988\\657197591.py:5: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  data = pd.concat([data, dataFrameFromDirectory(\"D:\\MLCourse\\emails\\spam\", \"spam\")])\n",
      "C:\\Users\\R-m-a\\AppData\\Local\\Temp\\ipykernel_37988\\657197591.py:6: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  data = pd.concat([data, dataFrameFromDirectory(\"D:\\MLCourse\\emails\\ham\", \"ham\")])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9616666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      1.00      0.98       482\n",
      "        spam       0.98      0.82      0.89       118\n",
      "\n",
      "    accuracy                           0.96       600\n",
      "   macro avg       0.97      0.91      0.94       600\n",
      "weighted avg       0.96      0.96      0.96       600\n",
      "\n",
      "Review: Free class now!!!\n",
      "Predicted Class: spam\n",
      "Review: Hi Bob, how about a game of golf tomorrow?\n",
      "Predicted Class: ham\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an empty DataFrame\n",
    "data = DataFrame({'message': [], 'class': []})\n",
    "\n",
    "# Load spam and ham emails into the DataFrame\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"D:\\MLCourse\\emails\\spam\", \"spam\")])\n",
    "data = pd.concat([data, dataFrameFromDirectory(\"D:\\MLCourse\\emails\\ham\", \"ham\")])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['message'], data['class'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure X_train and X_test are lists of strings\n",
    "X_train = X_train.tolist()\n",
    "X_test = X_test.tolist()\n",
    "\n",
    "# Initialize the CountVectorizer and transform the messages into counts\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier and train it\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = classifier.predict(X_test_counts)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Example new reviews\n",
    "new_reviews = [\n",
    "    \"Free class now!!!\",\n",
    "    \"Hi Bob, how about a game of golf tomorrow?\"\n",
    "]\n",
    "\n",
    "# Transform the new reviews into the same CountVectorizer features\n",
    "new_reviews_transformed = vectorizer.transform(new_reviews)\n",
    "\n",
    "# Predict the class for the new reviews\n",
    "predicted_classes = classifier.predict(new_reviews_transformed)\n",
    "\n",
    "# Display predictions\n",
    "for review, predicted_class in zip(new_reviews, predicted_classes):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Predicted Class: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
